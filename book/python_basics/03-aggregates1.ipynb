{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bc6a517",
   "metadata": {},
   "source": [
    "# Data Journalism Lesson 3: Aggregates, Part 1\n",
    "\n",
    "Learn how to take lots of little things and total them up into bigger things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a3d785",
   "metadata": {
    "tags": [
     "thebe-init",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Setup code for the notebook\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def check_groupby(result, expected):\n",
    "    \"\"\"\n",
    "    Check if the result of a groupby operation matches the expected result.\n",
    "    \"\"\"\n",
    "    # Check if the DataFrames are equal\n",
    "    try: \n",
    "        pd.testing.assert_frame_equal(result, expected, check_dtype=False, check_like=True)\n",
    "        display(HTML('<div style=\"background-color: #dff0d8; padding: 10px; border-radius: 5px;\">' +\n",
    "                 '<strong>Great work!</strong></div>'))\n",
    "    except AssertionError:\n",
    "        display(HTML('<div style=\"background-color: #f2dede; padding: 10px; border-radius: 5px;\">' +\n",
    "                 '<strong>Not quite!</strong> Make sure you are using the right dataframe and column names.</div>'))\n",
    "\n",
    "def check_sorted(result, expected):\n",
    "    \"\"\"\n",
    "    Check if the result of a groupby operation matches the expected result.\n",
    "    \"\"\"\n",
    "    # Check if the DataFrames are equal\n",
    "    try:\n",
    "        pd.testing.assert_frame_equal(result, expected, check_dtype=False, check_like=True)\n",
    "        display(HTML('<div style=\"background-color: #dff0d8; padding: 10px; border-radius: 5px;\">' +\n",
    "                 '<strong>Great work!</strong></div>'))\n",
    "    except AssertionError:\n",
    "        display(HTML('<div style=\"background-color: #f2dede; padding: 10px; border-radius: 5px;\">' +\n",
    "                 '<strong>Not quite!</strong> Make sure you are using the right dataframe.</div>'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e67375b",
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output",
     "thebe-init"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "state = \"Minnesota\"\n",
    "\n",
    "homes = pd.read_csv(f'../_static/nursing-homes/{state.lower()}.csv')\n",
    "\n",
    "expected = homes.groupby(\"county_parish\").count()\n",
    "expected_sorted = expected.sort_values(\"cms_certification_number_ccn\", ascending=False)\n",
    "expected_multi_group = homes.groupby([\"county_parish\", \"overall_rating\"]).count().sort_values(\"cms_certification_number_ccn\", ascending=False)\n",
    "\n",
    "# Get county with most nursing homes\n",
    "county_counts = homes['county_parish'].value_counts()\n",
    "top_county = county_counts.index[0]\n",
    "top_county_count = county_counts.iloc[0]\n",
    "\n",
    "toprow = (homes\n",
    " .groupby([\"county_parish\", \"overall_rating\"])\n",
    " .count()\n",
    " .sort_values(by=\"cms_certification_number_ccn\", ascending=False)\n",
    " .head(1).reset_index())\n",
    "toprow_county = toprow.iloc[0, 0]\n",
    "toprow_rating = toprow.iloc[0, 1]\n",
    "toprow_count = toprow.iloc[0, 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b48e5d",
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from myst_nb import glue\n",
    "\n",
    "# Glue variables for use elsewhere in the notebook\n",
    "glue(\"top_county\", top_county, display=False)\n",
    "glue(\"top_county_count\", f\"{top_county_count}\", display=False)\n",
    "glue(\"state\", state, display=False)\n",
    "glue(\"n_homes\", f\"{int(len(homes)):,}\")\n",
    "glue(\"toprow_county\", toprow_county, display=False)\n",
    "glue(\"toprow_rating\", f\"{toprow_rating}\", display=False)\n",
    "glue(\"toprow_count\", f\"{toprow_count}\", display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74909a86",
   "metadata": {},
   "source": [
    "## The Goal\n",
    "\n",
    "The goal of this lesson is to introduce you to one of the most fundamental and powerful concepts in data analysis: aggregation. You'll learn how to take large datasets with many individual records and summarize them into meaningful insights. We'll focus on using the `groupby()` and `agg()`/`count()` functions from pandas to group similar items together and calculate totals. By the end of this lesson, you'll be able to answer questions about the nursing homes in your state, but the techniques you learn can be applied to any subject or dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232e1c83",
   "metadata": {},
   "source": [
    "## What is Data Journalism?\n",
    "\n",
    "So far, in our philosophical discussion of data journalism, we’ve talked about how it’s interviewing data as a source, and one of your first steps is just knowing what is in your data. What does it look like? Now we’re going to take our first steps – a giant leap, really – into asking your data questions and getting answers. It’s one of the most powerful calculations you can do as a data journalist.\n",
    "\n",
    "Count things.\n",
    "\n",
    "No really.\n",
    "\n",
    "“Ninety percent of what I do is counting things,” said MaryJo Webster of the Star Tribune. “And so, to me, you could kind of think back to when you were a child and you were playing with a set of blocks or maybe Legos and you counted out how many blue ones do I have, how many red ones do I have. That is kind of what I do every day.”\n",
    "\n",
    "So what kind of stories can you do with that?\n",
    "\n",
    "“How many car crashes there were and how many were in this county versus that county?” she said. “How many were this year versus that year? Very simple count. You’re just counting.”\n",
    "\n",
    "It’s hard to explain to people who have never worked with data how important the simple act of counting is. Almost every data story you will ever work on will have a count in them – either one you will do or one done for you before you get the data. Almost every data story can be summarized into a few questions:\n",
    "\n",
    "How many of this thing are there where I live?\n",
    "How many of those things were there last year? Or five years ago?\n",
    "How does that many things compare to my state? The nation?\n",
    "Why is there that many or that few of these things?\n",
    "When I count up all the things, there aren’t any in this place. Why?\n",
    "There are, of course, more questions to ask of data. And we’ll get to those. But a shocking amount of data journalism starts with a simple count. How many of these things are there compared to this other thing?\n",
    "\n",
    "So let’s start there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdd7901",
   "metadata": {},
   "source": [
    "## The Basics\n",
    "\n",
    "One of the most basic bits of data analysis is just simply taking a lot of things – hundreds, thousands, millions of things – and putting them together somehow. Rarely ever do we want just one number. I’ll give you an example: Let’s pretend for a second that we have Spotify’s data. We have every song streamed in a year. Billions of records. Do we want to just count them up? One number? Is your annual Spotify Wrapped just one number that’s the total number of streams everyone played in a year? No, of course not.\n",
    "\n",
    "It’s streams – but put in groups. You, a user, are a group. How many songs did you play? How many times? What artists? What genres? And on and on. And with each group, we get a different number. An interesting number. A useful number.\n",
    "\n",
    "So how do you put things together?\n",
    "\n",
    "First, we need to load our libraries.\n",
    "\n",
    "Run this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b18eb3",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5320f46f",
   "metadata": {},
   "source": [
    "Now, let’s use a dataset that may not be interesting to you now – because you’re young – but it’s a critical public policy issue in the United States: Nursing homes. Quite simply, there aren’t enough of them. And in some places, there aren’t any at all, in spite of there being old people to take care of in those places. The number of nursing homes in your state – and where they are in your state – is a major issue that directly affects families all around you.\n",
    "\n",
    "For this exercise, you need to simply run this, filling in your state name where the blank is in all lowercase letters and replacing any spaces with a dash. Examples: nebraska and new-mexico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6692e8",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# Import the nursing homes data\n",
    "homes = pd.read_csv('../_static/nursing-homes/minnesota.csv')\n",
    "homes.head()  # Show the first few rows to check it loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9029d216",
   "metadata": {},
   "source": [
    "## Inspecting Data\n",
    "\n",
    "Now we can inspect the data we imported. What does it look like? What’s in it? What do we have to work with?\n",
    "\n",
    "To do that, we use `.head()` after the name of the variable we created above to show the headers and the first five rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea10bdd4",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# Show the first five rows\n",
    "homes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfe27f2",
   "metadata": {},
   "source": [
    "Let’s look at this. As you can see by the data, we have five nursing homes, which is what we expect from head(). But notice the first row – the headers. That is where most of the answers you are going to need are going to come from. You can see things like the provider_name and their address. If you scroll to the right, you’ll find more data – like their phone number, which is interesting for reporting purposes. You’ll see a column called county_parish that we’re going to use to find where these nursing homes are. You can keep scrolling right for a long time – there’s 103 columns in the data. Which might seem like a lot, but there are datasets with thousands of columns and millions of rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6f7492",
   "metadata": {},
   "source": [
    "## Answering questions with code\n",
    "\n",
    "There are {glue:text}`n_homes` nursing homes in {glue:text}`state` as of the latest data. But that doesn't tell us much. Let's explore more.\n",
    "\n",
    "The secret to writing code is that much of it is a pattern. With pandas, this is _especially_ true.\n",
    "\n",
    "To accomplish our goal, we start with the name of the data. Then, we use pandas' `groupby()` function, along with `count()` to do just what we’ve been talking about – take your data, put each row into groups. This thing here together, those things over there together. A massive amount of data analysis involves grouping like things together at some point.\n",
    "\n",
    "It’s important to understand in your mind what `groupby()` and `count()` are doing. It might be easiest to think about it like a package of Skittles candy. Your data, when you first get it, is like a pack of Skittles – all mixed up. What group_by does is puts the candy in little piles. Here’s an bag of Skittles dumped out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c86af9",
   "metadata": {},
   "source": [
    "```{figure} ../figures/ch3_i1.png\n",
    "---\n",
    "alt: skittles\n",
    "align: center\n",
    "---\n",
    "Ungrouped data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166f37a0",
   "metadata": {},
   "source": [
    "Now, using `groupby`, we can put them into piles. With Skittles, we group them by color. With data, we could do this with any column of data – dates, locations, types, ratings and so on. The list is endless. But notice – all of those things are not numbers. With the exception of dates, they’re names or labels or text of some variety. Rarely ever will you group something by a number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4500ff6",
   "metadata": {},
   "source": [
    "```{figure} ../figures/ch3_i2.png\n",
    "---\n",
    "alt: skittles\n",
    "align: center\n",
    "---\n",
    "Grouped data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4392a21",
   "metadata": {},
   "source": [
    "We need to put something in the parenthesis in `groupby()`. This time the something comes from that first row of our data. We are grouping data by one of the pieces of the data – a field, or column. If we’re trying to group by county or parish, which field or column in our data looks like it holds that information? Let’s use head again and take a look at the very top row in bold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2955a10d",
   "metadata": {},
   "source": [
    "```{admonition} Key Concept\n",
    "A column name – and only a column name – can go in `groupby`.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131eed3a",
   "metadata": {},
   "source": [
    "To know what we’re going to use in `groupby`, we need to take another peek at our data. We’ll do this here so we have those column names to refer to in the code blocks coming up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca64a01",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "homes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9353db13",
   "metadata": {},
   "source": [
    "That block of code you just ran has two hints for the code block you’ll have to complete later: What data are you using? What column in that data do you want to group by? Keep those in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fbbf43",
   "metadata": {},
   "source": [
    "### Exercise 1: Group by and count\n",
    "\n",
    "After we group our data together by the thing we want to group it by, we need to count how many things are in each group. We do that first by saying we want to summarize our data (a count is a part of a summary). To get a summary, we have to tell it what we want to summarize. So in this case, we want a count.\n",
    "\n",
    "Here’s the pattern. You fill in where there are blanks. What you fill in are the two hints from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf48e6c1",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "homes_grouped = _____.groupby(_____).count()\n",
    "\n",
    "check_groupby(homes_grouped, expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9038ae2b",
   "metadata": {},
   "source": [
    "In this case, we wanted to group together locations, signified by the field name `county_parish`. After we group the data, we need to count them up, using `count()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9c7b2b",
   "metadata": {},
   "source": [
    "### Exercise 2: Arranging data\n",
    "\n",
    "And when we run that, we get a list of counties with a count next to them. But it’s in alphabetical order. That doesn’t help us much. Usually we want to know where the most or the least are. So we’ll add another And Then Do This `.` and use `sort_values`. `sort_values` does what you think it does – it sorts data in order. By default, it’s in ascending order – smallest to largest. But if we want to know the county with the most homes, we need to sort it in descending order. The pattern looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf016b7",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "homes_sorted = homes.groupby(_____).count().sort_values(_____, ascending=False)\n",
    "\n",
    "check_sorted(homes_sorted, expected_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38d2170",
   "metadata": {},
   "source": [
    "And when we run that, you’ll see that {glue:text}`top_county` has the most nursing homes with {glue:text}`top_county_count`. But let me guess – without knowing anything about your state, I bet you that {glue:text}`top_county` just happens to be the most populated in {glue:text}`state`. We’ll cover this again and again, but here’s your first warning: be careful that what you’re looking at isn’t just a population map. In this case, it’s just an example of a pattern of code we’ll use over and over again. It is not news that {glue:text}`top_county` has the most nursing homes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae31b9e",
   "metadata": {},
   "source": [
    "### Exercise 3: Grouping by more than one thing\n",
    "\n",
    "We can, if we want, group by more than one thing. One of the most popular uses of this data is to compare nursing homes – the federal government has created a 5-star rating system, where 5 is the best and 1 is not. In the data you have, that rating is in the `overall_rating` column. So what if we looked at the ratings for each home in each county?\n",
    "\n",
    "The hint here is each. Any time you hear an editor or a reporter or someone say each, it probably means there’s a group by involved. Each county with each rating means there’s two!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f8b0a2",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "homes_grouped_by_rating = homes.groupby([_____, _____]).count().sort_values(_____, ascending=False)\n",
    "\n",
    "check_groupby(homes_grouped_by_rating, expected_multi_group)\n",
    "\n",
    "homes_grouped_by_rating.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a9ea55",
   "metadata": {},
   "source": [
    "Now there’s a ton to look at here. But what does it mean? If you haven’t looked at a lot of data before, it might not be immediately intuitive. Let’s take the first row. What that says is {glue:text}`toprow_county` had {glue:text}`toprow_count` homes with a {glue:text}`toprow_rating`-star rating. See how the columns are arranged? It’s the first column in our group_by, followed by the second, and then the total we created in the summarize. Which is the order you come to them when you read the code. Logical, eh?\n",
    "\n",
    "That first row might be interesting, it might not be. A few rows down, you might find a smaller county with a lot of 5-star homes for its size. Or the opposite – a smaller county with a lot of low-rated homes. Every state has economic and cultural reasons for just about everything that goes on there. Apply what you know about your state to that list, and stories will start popping into your head."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c713ee86",
   "metadata": {},
   "source": [
    ":::{admonition} Common Mistake\n",
    ":class: caution\n",
    "\n",
    "Remember earlier when I said we’d rarely ever group by a number? Didn’t we just do that? Yes, but … Remember a number is only a number if you would do math on it. Is a 5-Star Rating system a number? Yes! And No! We will do math on it, but it’s also a label too. A critical skill in data journalism is using logic and common sense, not rigid rules that something will always be this way or that.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24a22df",
   "metadata": {},
   "source": [
    "## The Recap\n",
    "\n",
    "In this lesson, we've explored the fundamental process of data aggregation using pandas. We learned how to use `groupby()` to organize our data into meaningful categories, and then used `count()` to calculate statistics for these groups, starting with counts. We also practiced arranging our results to highlight the most significant findings.\n",
    "\n",
    "The most important bit to remember is that analyzing data in pandas is a pattern: `data.function().function().function`.\n",
    "\n",
    "Remember, the power of this approach lies in its flexibility and scalability - the same basic pattern of grouping, summarizing, and arranging can be applied to datasets of any size and complexity. Whether you’re analyzing a single city’s crime data or billions of Spotify streams, these tools form the foundation of data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64a52ee",
   "metadata": {},
   "source": [
    "## Terms to Know\n",
    "\n",
    "- **Aggregation**: The process of combining multiple data points into a single summary statistic or result.\n",
    "- **groupby()**: A pandas function that separates data into groups based on one or more variables, allowing for subsequent operations to be performed on each group independently.\n",
    "- **count()**: A function that counts the number of rows in each group.\n",
    "- **reset_index()**: Used to turn the group labels back into columns after grouping.\n",
    "- **sort_values()**: Used to order rows in a dataset based on values in specified columns.\n",
    "- **value_counts()**: A shortcut to count unique values in a column.\n",
    "- **Pipe operator**: In pandas, you can use method chaining (dot notation) to chain together multiple operations."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
