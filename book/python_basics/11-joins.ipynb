{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7e38621",
   "metadata": {},
   "source": [
    "# Data Journalism Lesson 11: Joining DataFrames\n",
    "\n",
    "Learn how to join datasets together using pandas, a crucial skill for data journalists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f7da96",
   "metadata": {
    "tags": [
     "hide-input",
     "thebe-init"
    ]
   },
   "outputs": [],
   "source": [
    "# Setup code for the notebook\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# --- Helper functions for grading exercises ---\n",
    "\n",
    "def check_load_tidyverse(result):\n",
    "    # In Python, we just need pandas usually\n",
    "    if 'pd' in globals():\n",
    "        display(HTML('<div style=\"background-color: #dff0d8; padding: 10px; border-radius: 5px;\"><strong>Correct!</strong> Pandas is imported.</div>'))\n",
    "    else:\n",
    "        display(HTML('<div style=\"background-color: #f2dede; padding: 10px; border-radius: 5px;\"><strong>Not quite!</strong> Make sure you import the pandas library as pd.</div>'))\n",
    "\n",
    "def check_read_accidents(df, expected_rows):\n",
    "    if isinstance(df, pd.DataFrame) and df.shape[0] == expected_rows:\n",
    "         display(HTML(f'<div style=\"background-color: #dff0d8; padding: 10px; border-radius: 5px;\"><strong>Great work!</strong> You imported your state\\'s fatal car crashes ({expected_rows} rows).</div>'))\n",
    "    else:\n",
    "        display(HTML('<div style=\"background-color: #f2dede; padding: 10px; border-radius: 5px;\"><strong>Not quite!</strong> Check the file path and make sure you\\'ve loaded the data into a DataFrame named \\'accidents\\'.</div>'))\n",
    "\n",
    "def check_read_people(df, expected_rows):\n",
    "    if isinstance(df, pd.DataFrame) and df.shape[0] == expected_rows:\n",
    "         display(HTML(f'<div style=\"background-color: #dff0d8; padding: 10px; border-radius: 5px;\"><strong>Great work!</strong> You imported the records of people involved in fatal crashes ({expected_rows} rows).</div>'))\n",
    "    else:\n",
    "        display(HTML('<div style=\"background-color: #f2dede; padding: 10px; border-radius: 5px;\"><strong>Not quite!</strong> Check the file path and make sure you\\'ve loaded the data into a DataFrame named \\'people\\'.</div>'))\n",
    "\n",
    "def check_head_display(result):\n",
    "    # Simple check, assumes user ran .head()\n",
    "    display(HTML('<div style=\"background-color: #dff0d8; padding: 10px; border-radius: 5px;\"><strong>Code Ran.</strong> Make sure you see the first few rows of the DataFrame.</div>'))\n",
    "\n",
    "def check_join1(df, expected_rows, expected_cols):\n",
    "    if isinstance(df, pd.DataFrame) and df.shape[0] == expected_rows and df.shape[1] == expected_cols:\n",
    "        display(HTML(f'<div style=\"background-color: #dff0d8; padding: 10px; border-radius: 5px;\"><strong>Correct!</strong> You performed the inner join correctly using explicit column names. Result has {expected_rows} rows and {expected_cols} columns.</div>'))\n",
    "    elif isinstance(df, pd.DataFrame):\n",
    "         display(HTML(f'<div style=\"background-color: #f2dede; padding: 10px; border-radius: 5px;\"><strong>Almost!</strong> Check the join type and the \\'on\\' or \\'left_on\\'/\\'right_on\\' parameters. Your result has {df.shape[0]} rows and {df.shape[1]} columns. Expected {expected_rows} rows and {expected_cols} columns.</div>'))\n",
    "    else:\n",
    "        display(HTML('<div style=\"background-color: #f2dede; padding: 10px; border-radius: 5px;\"><strong>Not quite!</strong> Make sure your join results in a pandas DataFrame.</div>'))\n",
    "\n",
    "def check_join2(df, expected_rows, expected_cols):\n",
    "    if isinstance(df, pd.DataFrame) and df.shape[0] == expected_rows and df.shape[1] == expected_cols:\n",
    "        display(HTML(f'<div style=\"background-color: #dff0d8; padding: 10px; border-radius: 5px;\"><strong>Correct!</strong> You performed the inner join correctly letting pandas find common columns. Result has {expected_rows} rows and {expected_cols} columns.</div>'))\n",
    "    elif isinstance(df, pd.DataFrame):\n",
    "         display(HTML(f'<div style=\"background-color: #f2dede; padding: 10px; border-radius: 5px;\"><strong>Almost!</strong> Check the join type. Your result has {df.shape[0]} rows and {df.shape[1]} columns. Expected {expected_rows} rows and {expected_cols} columns.</div>'))\n",
    "    else:\n",
    "        display(HTML('<div style=\"background-color: #f2dede; padding: 10px; border-radius: 5px;\"><strong>Not quite!</strong> Make sure your join results in a pandas DataFrame.</div>'))\n",
    "\n",
    "def check_join3(df):\n",
    "    # Check if the result looks like a grouped count\n",
    "    if isinstance(df, pd.DataFrame) and 'COUNTYNAME' in df.columns and len(df.columns) == 2 and pd.api.types.is_numeric_dtype(df.iloc[:, 1]):\n",
    "        display(HTML('<div style=\"background-color: #dff0d8; padding: 10px; border-radius: 5px;\"><strong>Looks Good!</strong> You\\'ve filtered, grouped, and counted the deaths by county.</div>'))\n",
    "    else:\n",
    "        display(HTML('<div style=\"background-color: #f2dede; padding: 10px; border-radius: 5px;\"><strong>Not quite!</strong> Make sure you filter for INJ_SEV == 4, group by COUNTYNAME, and count the occurrences. The result should be a DataFrame with county names and counts.</div>'))\n",
    "\n",
    "# --- Load Data ---\n",
    "# Using Nebraska as default, as in the Rmd\n",
    "state_abbr = \"MN\"\n",
    "state_name = \"Minnesota\"\n",
    "\n",
    "# Construct file paths (adjust if data is local)\n",
    "base_url = \"../_static/fatal-accidents\"\n",
    "accidents_url = f\"{base_url}/{state_name.lower()}-accidents.csv\"\n",
    "people_url = f\"{base_url}/{state_name.lower()}-people.csv\"\n",
    "\n",
    "accidents_df = pd.read_csv(accidents_url)\n",
    "people_df = pd.read_csv(people_url)\n",
    "\n",
    "# --- Define Variables for Text and Exercises ---\n",
    "accidentcount = accidents_df.shape[0]\n",
    "accidentcols = accidents_df.shape[1]\n",
    "peoplecount = people_df.shape[0]\n",
    "peoplecols = people_df.shape[1]\n",
    "\n",
    "# Perform joins to get counts for glue variables\n",
    "join1_df = pd.DataFrame() # Initialize\n",
    "join2_df = pd.DataFrame() # Initialize\n",
    "# Join 1 (explicit 'on')\n",
    "join1_df = pd.merge(accidents_df, people_df, on=\"ST_CASE\", how=\"inner\")\n",
    "join1count = join1_df.shape[0]\n",
    "join1cols = join1_df.shape[1]\n",
    "\n",
    "# Join 2 (implicit common columns)\n",
    "# Find common columns first\n",
    "common_columns = list(set(accidents_df.columns) & set(people_df.columns))\n",
    "join2_df = pd.merge(accidents_df, people_df, on=common_columns, how=\"inner\")\n",
    "join2count = join2_df.shape[0]\n",
    "join2cols = join2_df.shape[1]\n",
    "\n",
    "county_language = (\"county\", \"counties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a327ac",
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from myst_nb import glue\n",
    "\n",
    "# Glue variables for use in markdown cells\n",
    "glue(\"state_name\", state_name, display=False)\n",
    "glue(\"accidentcount\", f\"{accidentcount:,}\", display=False)\n",
    "glue(\"accidentcols\", accidentcols, display=False)\n",
    "glue(\"peoplecount\", f\"{peoplecount:,}\", display=False)\n",
    "glue(\"peoplecols\", peoplecols, display=False)\n",
    "glue(\"join1count\", f\"{join1count:,}\", display=False)\n",
    "glue(\"join1cols\", join1cols, display=False)\n",
    "glue(\"join2count\", f\"{join2count:,}\", display=False)\n",
    "glue(\"join2cols\", join2cols, display=False)\n",
    "glue(\"county_singular\", county_language[0], display=False)\n",
    "glue(\"county_plural\", county_language[1], display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6039b2",
   "metadata": {},
   "source": [
    "## The Goal\n",
    "\n",
    "In this lesson, you'll learn how to join datasets, a crucial skill for data journalists. By the end of this tutorial, you'll understand how to use different types of joins (`merge` in pandas) to merge datasets based on common elements. You'll practice these techniques using real-world examples, working with federal fatal car accident data from the National Highway Traffic Safety Administration. These skills will enable you to work with more complex datasets and uncover deeper insights in your data journalism projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce1d65f",
   "metadata": {},
   "source": [
    "## What is Data Journalism?\n",
    "\n",
    "When asked about how long it took him to learn about joins, Chad Day of the AP gives a bit of a chuckle.\n",
    "\n",
    "\\\"I learned a lot more from all of the mistakes,\\\" he said.\n",
    "\n",
    "What are joins? Think of it this way -- you have two tables. One table, from the Census Bureau, has demographic data about counties in your state. The other, from your state's elections office, has information about registered voters in counties in your state. Both have data that you need to do your story. But because both have county names in them, you should be able to combine them together so you have one table with both demographic information and registered voters. A join is how you can merge those two tables together.\n",
    "\n",
    "It's a simple concept that is never that simple.\n",
    "\n",
    "\\\"You would think that you had something in one data set that would match up with something in another data set,\\\" Day said. \\\"And then you would find that there's no leading zeros. Or you would find that one has leading zeros, one doesn't. Or you would find that you want a one-to-one join. You want just to have the same count of records in this side that you have on this side. And you end up with seven or eight times that because you didn't realize that they were duplicates or all of this kind of stuff that's in the data.\\\"\n",
    "\n",
    "Easy joins are datasets that come from the same program within the same agency of government. The hard ones are when you have data from two different agencies -- maybe one state, one local. Maybe one federal, one state. That's when you find out everyone has opinions about how to store information. Capitalization, leading zeros, trailing spaces, even if you include the word \\\"County\\\" or \\\"Parish\\\" after the name. It all matters.\n",
    "\n",
    "Joins are going to put to the test how well you learned your data smells and how well you can think logically.\n",
    "\n",
    "\\\"If you don't do the proper preparation and all of the actual counting and basic-type sorting and filtering and all the basic stuff ahead of time, then joins are going to show all of the warts and problems with the way that you're thinking about the data,\\\" Day said."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fe8fe9",
   "metadata": {},
   "source": [
    "## The Basics\n",
    "\n",
    "Often, as data journalists, we're looking at data stored in multiple tables. In database world, they're called relational systems or relational databases. Why relational? Each table *relates* to the others. Here's an example: Most likely, you're a college student. Or you were a college student at some point. If you went to college sometime since the 1980s, your college ran on a relational database system.\n",
    "\n",
    "At the center of that database is a table -- a dataframe, if you will. In that table? Students. Each row is a student. It contains all the information about a student that doesn't change -- name, date of birth, student ID number, etc. That student ID number is a key -- it's how each table is going to be related back to the student.\n",
    "\n",
    "Ever checked out a book at the campus library? When they scanned your card, a database recorded what book you checked out and used your Student ID number to relate back to the student table, where your name is. Somewhere, there's a table of all the classes you took. Is your name, date of birth, home address and all that information attached to *every* class you took? No. But your student ID number is, and that's so it can be related back. That same class table is also related to the table of tuition bills, and I *guarantee* that one is connected to your name.\n",
    "\n",
    "Relational databases are very useful and are literally everywhere in the digital world. What made them so appealing back in the 1970s and 80s when they took off? Well, you weren't storing any more data than you needed. Back in the day, storage was **expensive**. Storing a single iPhone photo would cost hundreds of thousands of dollars in the 1970s. The storage you have on your iPhone would make you 1 percenter level rich if you went back in time.\n",
    "\n",
    "Storage, now, today, in our time, is cheap. But, some government databases have been around for decades. The cost to update them for modern computing is far more expensive than it's worth. As such, you're likely to run into relational databases in your work as a data journalist.\n",
    "\n",
    "One such database is the Fatality Analysis Reporting System (or FARS) from the National Highway Traffic Safety Administration. Every year since 1975, NHTSA -- pronounced \\\"Nit-Sah\\\" by transportation nerds -- has gathered data on every fatal car crash in the United States. A mind-boggling amount of information is available about each and every crash that killed someone going back a long time. And that data has been used by traffic engineers to make cars and the roads they drive on safer.\n",
    "\n",
    "In 2002, I used FARS data to write about a stretch of highway in Pasco County, Florida, which is one of the nation's most deadly places to walk across the street. I looked at deaths from 1990-2000 and wrote this section of that story:\n",
    "\n",
    ">  Who dies on U.S. 19, when they die and where they die follow distinct patterns. A Times analysis of data from 1990 to 2000 found that most are middle aged men who try to cross the road . . .\n",
    ">  * At night (88 percent).\n",
    ">  * Where there are no street lights (74 percent).\n",
    ">  * Away from pedestrian crosswalks (76 percent).\n",
    ">  * After drinking alcohol (55 percent).\n",
    ">\n",
    ">Weather seldom is a factor.\n",
    "\n",
    "After the story ran, the county added lighting, signs and more crosswalk signage, and the number of deaths declined.\n",
    "\n",
    "How did I find all that out? Joining tables together.\n",
    "\n",
    "First we'll start with libraries. We'll need pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732cf6bc",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d722c06",
   "metadata": {},
   "source": [
    "Now we're going to load two of the tables in FARS. There's 34 of them, by the way. We're going to load two of the main tables -- the accident record, which is the key to everything, and the person record, which has information about every person involved in the accident. Want to know the average age of someone killed in a car crash? You really only need the person record. Need to know geographic info, time of day, what kind of roadway the accident happened on and *then* average together the ages? You'll need a join.\n",
    "\n",
    "We'll start with the accident record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751d88f4",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# Load the accidents data\n",
    "accidents = pd.read_csv(\"../_static/fatal-accidents/minnesota-accidents.csv\")\n",
    "accidents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8387a6",
   "metadata": {},
   "source": [
    "Now we're going to load the person record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d96454c",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# Load the people data\n",
    "people = pd.read_csv(\"../_static/fatal-accidents/minnesota-people.csv\")\n",
    "people.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4907ef13",
   "metadata": {},
   "source": [
    "The trick to joining data is finding the columns that are the common element. Let's look at the accidents data first and find the column that would contain key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b82eea",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "accidents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21696a2a",
   "metadata": {},
   "source": [
    "Major datasets like FARS have extensive documentation that go with them. Any serious data creation operation maintains serious documentation that will tell you what each and every column contains, what choices were made, what does what. Normally, I would tell you to go [read the documentation](https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/813556) but FARS is complex, and the documentation is 669 pages long.\n",
    "\n",
    "The column you are looking for here is `ST_CASE`. The `ST_CASE` number is a unique number given to an accident *in that year*. It's important to know it's only for the year. The very first accident in your dataset will follow the same pattern that every state follows -- the state number, followed by a four digit number representing what accident this is chronologically in the state. For example: Alabama is state 1. So its first `ST_CASE` is 10001. Nebraska is state 31. Its first `ST_CASE` is 310001. This data is for 2022. What happens in 2023? Those `ST_CASE` numbers repeat. That's why it's important to know they repeat year after year.\n",
    "\n",
    "For us to join this data, we have to have the **same** key in our person data. Do we?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf40916",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "people.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1217a5f7",
   "metadata": {},
   "source": [
    "Good news. There's `ST_CASE`. We can join this data together. Would have been a rather pointless setup if we couldn't, eh?\n",
    "\n",
    "And now, we've arrived at the point where we can join the data. The problem we now face is what *kind* of join do we want to do? There's multiple kinds. In pandas, the main function is `pd.merge()`. We can specify the type of join using the `how` parameter:\n",
    "\n",
    "- `how='inner'` (default): Keeps only rows where the key exists in **both** DataFrames.\n",
    "- `how='left'`: Keeps all rows from the **left** DataFrame and matching rows from the right. Fills with `NaN` where there's no match in the right.\n",
    "- `how='right'`: Keeps all rows from the **right** DataFrame and matching rows from the left. Fills with `NaN` where there's no match in the left.\n",
    "- `how='outer'`: Keeps all rows from **both** DataFrames. Fills with `NaN` where there's no match in the other DataFrame.\n",
    "\n",
    "```{image} ../figures/joins.png\n",
    ":alt: Visual representation of different join types\n",
    ":width: 600px\n",
    ":align: center\n",
    "```\n",
    "*(Image credit: [Julia Silge](https://juliasilge.com/blog/joining-airport-data/))*\n",
    "\n",
    "The best way to think about this is to think of your data as two sheets of paper -- the accidents sheet is on the left, the people sheet is on the right (when calling `pd.merge(accidents, people, ...)`). A `left` join would take all data from the accidents sheet and keep *only* the data that matched from the right sheet. The `right` join is the opposite -- all people data is kept, and only the matching accidents data is kept.\n",
    "\n",
    "The `inner` join keeps only the data where both match. In my career, the inner join is the one I've used the most. If a car accident happened somewhere that wasn't a state, do we want to know about it? (Answer: Kinda. A car accident on the moon would be news). And, often, looking at the results of that inner join are interesting -- how many fatal accidents don't involve people? That would seem to be bad data. So `inner` join it is because more often than not, what we care about is valid data that matches.\n",
    "\n",
    "Joining in pandas is easiest when the column names you want to join on are the same. Since this data is from the same source, we are just that lucky. But for the sake of learning, we're going to join data the hard way (explicitly naming the join column) and then the easy way (letting pandas figure it out).\n",
    "\n",
    "### Exercise 1: joining the hard way\n",
    "\n",
    "The hard way, in spite of its name, isn't that hard. We just have to tell `pd.merge` what column(s) to join on using the `on` parameter (if the column name is the same in both DataFrames) or the `left_on` and `right_on` parameters (if the names are different).\n",
    "\n",
    "We'll merge `accidents` (left DataFrame) with `people` (right DataFrame) using an `inner` join. The common column is `ST_CASE`. Since the name is the same in both, we can use the `on` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a363018",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "joined_hard = pd.merge(accidents, people, on=\"____\", how=\"inner\")\n",
    "\n",
    "print(f\"Joined DataFrame shape: {joined_hard.shape}\")\n",
    "print(joined_hard.head())\n",
    "\n",
    "check_join1(joined_hard, join1count, join1cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f900b9",
   "metadata": {},
   "source": [
    "Okay, we get a table, but did it work?\n",
    "\n",
    "Whenever you are joining tables, you have to think about what you expect. Given the logic you gave it, how many rows should you have?\n",
    "\n",
    "In your accident data, you have {glue:text}`accidentcount` rows, and in people, you have {glue:text}`peoplecount` rows. Using an inner join, where you are **keeping all rows that match in both tables**, how many rows should you expect?\n",
    "\n",
    "If you said {glue:text}`peoplecount`, gold star. Logically speaking, people involved in a fatal car crash should be related to a fatal car crash. There can be more than one person involved in a crash -- passengers, other drivers, etc. -- but every one of them should be associated with a crash. Otherwise, why are they in this dataset? How many rows did our join produce? {glue:text}`join1count`.\n",
    "\n",
    "A harder question, however, is how many *columns* did our join produce?\n",
    "\n",
    "Whenever you join two tables together with `on=`, the join key column (`ST_CASE` here) is only included once in your joined table. So while `ST_CASE` is in both original DataFrames, it will only appear once in our new dataset.\n",
    "\n",
    "But look at your data closer. Notice how some columns might have `_x` or `_y` suffixes? If you keep scrolling, you might find a bunch more. By default, if there are columns (other than the join key) with the same name in both the left and right DataFrames, pandas adds `_x` to the column name from the left DataFrame and `_y` to the column name from the right DataFrame to avoid ambiguity.\n",
    "\n",
    "In our data, we have {glue:text}`accidentcols` columns in accidents and {glue:text}`peoplecols` in people. How many does our join create? {glue:text}`join1cols`. Why is it not simply `accidentcols + peoplecols - 1` (subtracting 1 for the single `ST_CASE` column)? Because there are other columns with the same name in both DataFrames! Pandas keeps both versions, adding the `_x` and `_y` suffixes.\n",
    "\n",
    "How many shared columns are there besides `ST_CASE`? We could count the columns ending in `_x` or `_y`, or we could try joining differently.\n",
    "\n",
    "### Exercise 2: joining the easy way\n",
    "\n",
    "If you want to join on *all* columns that have the same name in both DataFrames, you can simply omit the `on`, `left_on`, and `right_on` parameters. Pandas will automatically identify all common column names and use them as the join keys.\n",
    "\n",
    "Let's try joining `accidents` and `people` again, this time letting pandas find all common columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0babd42b",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "joined_easy = pd.merge(____, ____, how=\"inner\")\n",
    "\n",
    "print(f\"Joined DataFrame shape: {joined_easy.shape}\")\n",
    "print(joined_easy.head())\n",
    "\n",
    "check_join2(joined_easy, join2count, join2cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6969b12e",
   "metadata": {},
   "source": [
    "Let's look carefully at our data. How many rows do we get? {glue:text}`join2count`. How many did we get with our hard way join? {glue:text}`join1count`. No difference. That's good. How about columns? The hard way we got {glue:text}`join1cols`. Now? {glue:text}`join2cols`. That's how many columns (including `ST_CASE`) were common between the two tables. By joining on *all* of them, we avoid the `_x` and `_y` suffixes for those columns, resulting in fewer total columns.\n",
    "\n",
    "Why learn both ways? The easy way (omitting `on`) only works when:\n",
    "1. You *want* to join on all columns that happen to share the same name.\n",
    "2. The columns you want to join on *do* have the exact same name.\n",
    "\n",
    "Often, your join keys might have slightly different names (e.g., `state_id` vs `stateID`) or you only want to join on a specific subset of common columns. In those cases, you *must* use `on` or `left_on`/`right_on` to explicitly tell pandas how to perform the merge. NHTSA has been working on and improving FARS since 1975, so the data is well-structured. Real-world data is often messier.\n",
    "\n",
    "### Exercise 3: using our joined data\n",
    "\n",
    "Let's use our new joined data. We'll use `joined_easy` (the result from Exercise 2, which has fewer columns). Let's use what we've learned and ask some questions. Let's start with a simple question: How many people died in car crashes in each {glue:text}`county_singular`?\n",
    "\n",
    "To do this, you have to know there is a column called `INJ_SEV`, which is short for injury severity. It's from the people dataframe. An injury severity code of 4 means the person died. And, in the accidents dataframe, there is a column called `COUNTYNAME`. Since you joined the two tables together, you have them both in `joined_easy`.\n",
    "\n",
    "You'll need to:\n",
    "1. Filter `joined_easy` to keep only rows where `INJ_SEV` is 4.\n",
    "2. Group the filtered data by `COUNTYNAME`.\n",
    "3. Count the number of rows in each group (this represents the number of deaths).\n",
    "4. Sort the results in descending order to see the counties with the most deaths first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcf95d9",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "county_deaths = (\n",
    "    joined_easy\n",
    "    .query(\"INJ_SEV == ____\")\n",
    "    .groupby(\"____\")\n",
    "    .size()\n",
    "    .reset_index(name=\"death_count\")\n",
    "    .sort_values(by=\"_____\", ascending=False)\n",
    ")\n",
    "\n",
    "print(county_deaths.head())\n",
    "\n",
    "# Check the result\n",
    "check_join3(county_deaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd31bf1",
   "metadata": {},
   "source": [
    "And now you have a paragraph to add to a story about a fatal car crash in {glue:text}`state_name`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64912d93",
   "metadata": {},
   "source": [
    "## The Recap\n",
    "\n",
    "Throughout this lesson, you've learned important techniques for joining two datasets using pandas `merge`. You've explored different types of joins (`inner`, `left`, `right`, `outer` specified with the `how` parameter) and focused on `inner` joins to merge car accident data with the people who were involved in those crashes. You learned how to specify the join keys explicitly using `on` or `left_on`/`right_on`, and how pandas can automatically join on all common columns if keys aren't specified. Remember, choosing the right type of join and correctly identifying the join keys are crucial for maintaining data integrity and getting accurate results. As you continue to learn, these skills will allow you to work with more diverse and complex datasets, enabling you to tell more comprehensive and insightful stories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c15c46c",
   "metadata": {},
   "source": [
    "## Terms to Know\n",
    "\n",
    "- **`pandas.merge()`**: The primary function in pandas for combining DataFrames based on common columns or indices.\n",
    "- **Join Key**: The column(s) used to match rows between DataFrames during a merge operation.\n",
    "- **`how` parameter**: Used in `pd.merge()` to specify the type of join: `'inner'`, `'left'`, `'right'`, `'outer'`.\n",
    "- **`on` parameter**: Used in `pd.merge()` to specify the column name(s) to join on when the key column(s) have the same name in both DataFrames.\n",
    "- **`left_on`, `right_on` parameters**: Used in `pd.merge()` to specify the key column(s) when they have different names in the left and right DataFrames.\n",
    "- **Inner Join (`how='inner'`)**: Keeps only rows where the join key exists in both DataFrames.\n",
    "- **Left Join (`how='left'`)**: Keeps all rows from the left DataFrame and matching rows from the right DataFrame.\n",
    "- **Right Join (`how='right'`)**: Keeps all rows from the right DataFrame and matching rows from the left DataFrame.\n",
    "- **Outer Join (`how='outer'`)**: Keeps all rows from both DataFrames.\n",
    "- **Suffixes (`_x`, `_y`)**: Added by pandas to non-key column names that are identical in both DataFrames during a merge to avoid ambiguity (unless joining on those columns).## Terms to Know\","
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
